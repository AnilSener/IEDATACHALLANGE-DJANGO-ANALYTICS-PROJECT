{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from time import time\n",
      "import pymongo\n",
      "import gc\n",
      "from pymongo import MongoClient\n",
      "import random\n",
      "from pandas import concat\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "from sklearn.linear_model import RidgeClassifier\n",
      "from sklearn.svm import LinearSVC\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.linear_model import Perceptron\n",
      "from sklearn.linear_model import PassiveAggressiveClassifier\n",
      "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.neighbors import NearestCentroid\n",
      "from sklearn.utils.extmath import density\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.decomposition import TruncatedSVD\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn import metrics\n",
      "import matplotlib.pyplot as plt\n",
      "import nltk\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "import itertools\n",
      "from nltk.corpus import sentiwordnet as swn\n",
      "wnl = WordNetLemmatizer()\n",
      "\n",
      "random.seed(121)"
     ],
     "language": "python",
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "import configparser\n",
      "config = configparser.ConfigParser()\n",
      "config.read('/root/PycharmProjects/IEdatachallange/app.conf')\n",
      "from mongoengine.connection import connect,disconnect\n",
      "connection=connect(db=\"hotelapp\", username=\"hoteladmin\", password=\"hoteladmin\")"
     ],
     "language": "python",
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 2,
     "source": [
      "Sentiment Analysis with Words"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "client = MongoClient('localhost',27017 )\n",
      "db = client.hotelapp\n",
      "hotelReview = db.hotel_review\n",
      "hotelSentiment = db.hotel_sentiment"
     ],
     "language": "python",
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "Format DataFrame"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:5: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n",
        "-c:7: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n",
        "-c:9: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:11: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n",
        "-c:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:20: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n",
        "-c:22: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n",
        "-c:24: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_index,col_indexer] = value instead\n"
       ]
      }
     ],
     "input": [
      "df= pd.DataFrame(list(hotelReview.find({\"review\": {\"$exists\": \"true\"}}, {\"review\":1, \"rating\":1, \"_id\":0})))\n",
      "df5 = df[df['rating'] == 5]\n",
      "df5['rating'] = 3\n",
      "df4 = df[df['rating'] == 4]\n",
      "df4['rating'] = 3\n",
      "df3 = df[df['rating'] == 3]\n",
      "df3['rating']= 2\n",
      "df2 = df[df['rating'] == 2]\n",
      "df2['rating']= 1\n",
      "df1 = df[df['rating'] == 1]\n",
      "df = concat([df5, df4, df3, df3, df3, df2, df2, df2, df1, df1, df1])\n",
      "\n",
      "dfTitle = pd.DataFrame(list(hotelReview.find({\"review\": {\"$exists\": \"true\"}}, {\"title\":1, \"rating\":1, \"_id\":0})))\n",
      "df5 = dfTitle[dfTitle['rating'] == 5]\n",
      "df5['rating'] = 3\n",
      "df4 = dfTitle[dfTitle['rating'] == 4]\n",
      "df4['rating'] = 3\n",
      "df3 = dfTitle[dfTitle['rating'] == 3]\n",
      "df3['rating']= 2\n",
      "df2 = dfTitle[dfTitle['rating'] == 2]\n",
      "df2['rating']= 1\n",
      "df1 = dfTitle[dfTitle['rating'] == 1]\n",
      "dfTitle = concat([df5, df4, df3, df3, df2, df2, df1, df1])"
     ],
     "language": "python",
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "lem = WordNetLemmatizer()\n",
      "a = df[\"review\"].tolist()\n",
      "for i in range(len(a)):\n",
      "    a[i] = nltk.sent_tokenize(a[i])\n",
      "    a[i] = [nltk.word_tokenize(sent) for sent in a[i]]\n",
      "    b = []\n",
      "    for sent in a[i]:\n",
      "        lemma = [lem.lemmatize(word) for word in sent]\n",
      "        b.append(lemma)\n",
      "    a[i] = b\n",
      "    a[i] = list(itertools.chain(*a[i]))\n",
      "    a[i] = \" \".join(a[i])\n",
      "df[\"review\"] = a"
     ],
     "language": "python",
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "SentiWordnet"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "dfSenti= pd.DataFrame(list(hotelReview.find({\"review\": {\"$exists\": \"true\"}}, {\"review\":1, \"rating\":1, \"_id\":0})))\n",
      "allReviews = []\n",
      "\n",
      "for i in range(dfSenti.shape[0]):\n",
      "    sentences = nltk.sent_tokenize(dfSenti.ix[i,1][1:-1])\n",
      "    stokens = [nltk.word_tokenize(sent) for sent in sentences]\n",
      "    stokens = list(itertools.chain(*stokens))\n",
      "    lemma = [wnl.lemmatize(t) for t in stokens]\n",
      "    tagged = nltk.pos_tag(lemma)\n",
      "    scores = []\n",
      "    for tag in tagged:\n",
      "        if tag[1].startswith('NN'):\n",
      "            synsets = list(swn.senti_synsets(tag[0], 'n'))\n",
      "            if len(synsets) > 0:\n",
      "                scores.append(str(synsets[0].pos_score()))\n",
      "        elif tag[1].startswith('JJ'):\n",
      "            synsets = list(swn.senti_synsets(tag[0], 'a'))\n",
      "            if len(synsets) > 0:\n",
      "                scores.append(str(synsets[0].pos_score()))\n",
      "        elif tag[1].startswith('V'):\n",
      "            synsets = list(swn.senti_synsets(tag[0], 'v'))\n",
      "            if len(synsets) > 0:\n",
      "                scores.append(str(synsets[0].pos_score()))\n",
      "        elif tag[1].startswith('R'):\n",
      "            synsets = list(swn.senti_synsets(tag[0], 'r'))\n",
      "            if len(synsets) > 0:\n",
      "                scores.append(str(synsets[0].pos_score()))\n",
      "    allReviews.append(\", \".join(scores))\n",
      "    \n",
      "dfSenti['Senti_Scores'] = allReviews\n",
      "\n",
      "dfSenti = dfSenti[[\"rating\", \"Senti_Scores\"]]\n",
      "df5 = dfSenti[dfSenti['rating'] == 5]\n",
      "df5['rating'] = 3\n",
      "df4 = dfSenti[dfSenti['rating'] == 4]\n",
      "df4['rating'] = 3\n",
      "df3 = dfSenti[dfSenti['rating'] == 3]\n",
      "df3['rating']= 2\n",
      "df2 = dfSenti[dfSenti['rating'] == 2]\n",
      "df2['rating']= 1\n",
      "df1 = dfSenti[dfSenti['rating'] == 1]\n",
      "dfSenti = concat([df5, df4, df3, df3, df2, df2, df1, df1])\n",
      "dfSenti.head()"
     ],
     "language": "python"
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "Benchmark Function. It takes any classification algorithm and returns a confusion matrix, and metric scores along with the top words it used to classify"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "def benchmark(clf, data, ngram=(1,1), text_vectorizer= 'hash', dim_reduce='Ch2', k_variables=1000, top10=True, feature_names=True, report=True, matrix=True):\n",
      "    def Append(row):\n",
      "        corpus.append(row)\n",
      "    \n",
      "    corpus = []\n",
      "    data.ix[:,1].apply(Append)\n",
      "    \n",
      "    if text_vectorizer == 'tfi':\n",
      "        vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=ngram, max_df=0.5, stop_words='english', lowercase=True)\n",
      "    \n",
      "    elif text_vectorizer == 'count':\n",
      "        vectorizer = CountVectorizer(ngram_range=ngram, lowercase=True)\n",
      "        \n",
      "    elif text_vectorizer == 'hash':\n",
      "        vectorizer = HashingVectorizer(n_features=2000, norm='l1', non_negative=True, lowercase=True, stop_words='english', ngram_range=ngram)\n",
      "        \n",
      "    X = vectorizer.fit_transform(corpus)\n",
      "    \n",
      "    if text_vectorizer == 'hash':\n",
      "        Xdf = pd.DataFrame(X.toarray(),index=corpus)\n",
      "    else:\n",
      "        Xdf = pd.DataFrame(X.toarray(),index=corpus,columns=vectorizer.get_feature_names())\n",
      "    Xdf['zzRating'] = data.ix[:,0].values.astype(int)\n",
      "\n",
      "\n",
      "    X_train, X_test = train_test_split(Xdf, train_size = .7, random_state= 111)\n",
      "    y_train, y_test = X_train[:,X_train.shape[1] - 1], X_test[:,X_test.shape[1] - 1]\n",
      "    X_train, X_test = X_train[:,0:-1], X_test[:,0:-1]\n",
      "\n",
      "    if dim_reduce == 'Ch2':\n",
      "        ch2 = SelectKBest(chi2, k= k_variables)\n",
      "        b = ch2.fit(X_train, y_train)\n",
      "        X_train, X_test = X_train[:, b.get_support()], X_test[:, b.get_support()]\n",
      "    elif dim_reduce == 'SVD':\n",
      "        svd = TruncatedSVD(n_components=2, random_state=42)\n",
      "        X_train, X_test = svd.fit_transform(X_train), svd.fit_transform(X_test)\n",
      "\n",
      "\n",
      "    print('_' * 80)\n",
      "    print(\"Training: \")\n",
      "    print(clf)\n",
      "    t0 = time()\n",
      "    clf.fit(X_train, y_train)\n",
      "    train_time = time() - t0\n",
      "\n",
      "    t0 = time()\n",
      "    pred = clf.predict(X_test)\n",
      "    test_time = time() - t0\n",
      "\n",
      "    score = metrics.f1_score(y_test, pred)\n",
      "    print(\"F1 Score:   %0.3f\" % score)\n",
      "    \n",
      "    if text_vectorizer != 'hash':\n",
      "        if top10 and feature_names is not None:\n",
      "            if hasattr(clf, 'coef_'):\n",
      "                    print(\"top 10 keywords per class:\")\n",
      "                    for i in range(3):\n",
      "                        top10 = np.argsort(clf.coef_[i])[-20:]\n",
      "                        feature_names = Xdf.ix[:,:-1]\n",
      "                        feature_names = feature_names.ix[:,b.get_support()].columns\n",
      "                        print(feature_names[top10])\n",
      "\n",
      "            if hasattr(clf, 'feature_importances_'):\n",
      "                print(\"top 10 keywords per class:\")\n",
      "                top10 = np.argsort(clf.feature_importances_)[-30:]\n",
      "                feature_names = Xdf.ix[:,:-1]\n",
      "                feature_names = feature_names.ix[:,b.get_support()].columns\n",
      "                print(feature_names[top10])\n",
      "\n",
      "    if report != None:\n",
      "        print(\"classification report:\")\n",
      "        print(metrics.classification_report(y_test, pred,\n",
      "                                            target_names=['1','2','3']))\n",
      "    \n",
      "    if matrix != None:\n",
      "        print(\"confusion matrix:\")\n",
      "        print(pd.DataFrame(metrics.confusion_matrix(y_test, pred), columns=['Bad','Neutral','Good'], index= ['Bad','Neutral','Good']))\n",
      "        conf = metrics.confusion_matrix(y_test, pred)\n",
      "\n",
      "    clf_descr = str(clf).split('(')[0]\n",
      "    return clf_descr, score, train_time, test_time, clf #probs,pred #conf"
     ],
     "language": "python",
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "Run Classifier Function"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "________________________________________________________________________________\n",
        "Training: \n",
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='entropy', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=50, n_jobs=1,\n",
        "            oob_score=False, random_state=223, verbose=0)\n",
        "F1 Score:   0.972"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       1.00      0.96      0.98       675\n",
        "          2       0.99      0.94      0.96      1432\n",
        "          3       0.96      0.99      0.98      3017\n",
        "\n",
        "avg / total       0.97      0.97      0.97      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad      645        3    27\n",
        "Neutral    0     1339    93\n",
        "Good       3       16  2998\n",
        "\n"
       ]
      }
     ],
     "input": [
      "clf_descr, score, train_time, test_time, clf= benchmark(RandomForestClassifier(bootstrap=True,\n",
      "            criterion='entropy', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=223, verbose=0), df, k_variables=1000, text_vectorizer='hash')"
     ],
     "language": "python",
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "\"from sklearn.externals import joblib\\njoblib.dump(clf, '/data1/home/anil/Desktop/IEdatachallange/hotelapp/analytics/models/senti_model.pkl')\\nprint('')\""
       ],
       "metadata": {}
      }
     ],
     "input": [
      "'''from sklearn.externals import joblib\n",
      "joblib.dump(clf, '/data1/home/anil/Desktop/IEdatachallange/hotelapp/analytics/models/senti_model.pkl')\n",
      "print('')'''"
     ],
     "language": "python",
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "Performance Benchmark Plot"
     ]
    },
    {
     "cell_type": "heading",
     "metadata": {},
     "level": 3,
     "source": [
      "Run All Algorithms at Once"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "================================================================================\n",
        "Ridge Classifier\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
        "        max_iter=None, normalize=False, solver='lsqr', tol=0.01)\n",
        "F1 Score:   0.608"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.90      0.11      0.19       675\n",
        "          2       0.56      0.32      0.41      1432\n",
        "          3       0.68      0.95      0.80      3017\n",
        "\n",
        "avg / total       0.68      0.67      0.61      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad       72      226   377\n",
        "Neutral    5      460   967\n",
        "Good       3      134  2880\n",
        "\n",
        "================================================================================"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Perceptron\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
        "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=False,\n",
        "      verbose=0, warm_start=False)\n",
        "F1 Score:   0.700"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.74      0.49      0.59       675\n",
        "          2       0.65      0.41      0.50      1432\n",
        "          3       0.74      0.92      0.82      3017\n",
        "\n",
        "avg / total       0.71      0.72      0.70      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad      329      124   222\n",
        "Neutral   82      582   768\n",
        "Good      34      195  2788\n",
        "\n",
        "================================================================================"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Passive-Aggressive\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "PassiveAggressiveClassifier(C=1.0, fit_intercept=True, loss='hinge',\n",
        "              n_iter=50, n_jobs=1, random_state=None, shuffle=False,\n",
        "              verbose=0, warm_start=False)\n",
        "F1 Score:   0.692"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.79      0.32      0.46       675\n",
        "          2       0.62      0.46      0.53      1432\n",
        "          3       0.74      0.93      0.82      3017\n",
        "\n",
        "avg / total       0.71      0.72      0.69      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad      217      201   257\n",
        "Neutral   40      658   734\n",
        "Good      16      204  2797\n",
        "\n",
        "================================================================================"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Forest\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)\n",
        "F1 Score:   0.953"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.97      0.95      0.96       675\n",
        "          2       0.93      0.94      0.93      1432\n",
        "          3       0.96      0.96      0.96      3017\n",
        "\n",
        "avg / total       0.95      0.95      0.95      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad      639        6    30\n",
        "Neutral    9     1345    78\n",
        "Good      14      102  2901\n",
        "\n",
        "================================================================================"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "L2 penalty\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.001, verbose=0)\n",
        "F1 Score:   0.654"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.79      0.22      0.35       675\n",
        "          2       0.58      0.39      0.47      1432\n",
        "          3       0.71      0.94      0.81      3017\n",
        "\n",
        "avg / total       0.69      0.69      0.65      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad      150      230   295\n",
        "Neutral   24      565   843\n",
        "Good      17      171  2829\n",
        "\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
        "       loss='hinge', n_iter=50, n_jobs=1, penalty='l2', power_t=0.5,\n",
        "       random_state=None, shuffle=False, verbose=0, warm_start=False)\n",
        "F1 Score:   0.461"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       1.00      0.01      0.03       675\n",
        "          2       0.57      0.03      0.06      1432\n",
        "          3       0.60      1.00      0.75      3017\n",
        "\n",
        "avg / total       0.64      0.60      0.46      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad       10       30   635\n",
        "Neutral    0       44  1388\n",
        "Good       0        3  3014\n",
        "\n",
        "================================================================================"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "L1 penalty\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l1',\n",
        "     random_state=None, tol=0.001, verbose=0)\n",
        "F1 Score:   0.694"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.75      0.35      0.48       675\n",
        "          2       0.60      0.47      0.53      1432\n",
        "          3       0.75      0.91      0.82      3017\n",
        "\n",
        "avg / total       0.71      0.72      0.69      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad      235      212   228\n",
        "Neutral   57      675   700\n",
        "Good      20      243  2754\n",
        "\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
        "       loss='hinge', n_iter=50, n_jobs=1, penalty='l1', power_t=0.5,\n",
        "       random_state=None, shuffle=False, verbose=0, warm_start=False)\n",
        "F1 Score:   0.556"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.77      0.07      0.13       675\n",
        "          2       0.52      0.20      0.29      1432\n",
        "          3       0.65      0.97      0.78      3017\n",
        "\n",
        "avg / total       0.63      0.64      0.56      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad       47      176   452\n",
        "Neutral   14      284  1134\n",
        "Good       0       82  2935\n",
        "\n",
        "================================================================================"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elastic-Net penalty\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
        "       loss='hinge', n_iter=50, n_jobs=1, penalty='elasticnet',\n",
        "       power_t=0.5, random_state=None, shuffle=False, verbose=0,\n",
        "       warm_start=False)\n",
        "F1 Score:   0.465"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       1.00      0.02      0.04       675\n",
        "          2       0.57      0.03      0.07      1432\n",
        "          3       0.60      1.00      0.75      3017\n",
        "\n",
        "avg / total       0.65      0.60      0.47      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad       14       33   628\n",
        "Neutral    0       50  1382\n",
        "Good       0        4  3013\n",
        "\n",
        "================================================================================"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NearestCentroid (aka Rocchio classifier)\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
        "F1 Score:   0.564"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.30      0.66      0.41       675\n",
        "          2       0.41      0.35      0.38      1432\n",
        "          3       0.77      0.62      0.69      3017\n",
        "\n",
        "avg / total       0.61      0.55      0.56      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad      445      121   109\n",
        "Neutral  488      497   447\n",
        "Good     560      588  1869\n",
        "\n",
        "================================================================================"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Naive Bayes\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "F1 Score:   0.728"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.57      0.64      0.60       675\n",
        "          2       0.60      0.55      0.58      1432\n",
        "          3       0.82      0.83      0.83      3017\n",
        "\n",
        "avg / total       0.73      0.73      0.73      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad      431      153    91\n",
        "Neutral  183      791   458\n",
        "Good     138      365  2514\n",
        "\n",
        "================================================================================"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LinearSVC with L1-based feature selection\n",
        "________________________________________________________________________________"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training: \n",
        "L1LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
        "      intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "      random_state=None, tol=0.0001, verbose=0)\n",
        "[ 3.  3.  3. ...,  3.  3.  3.]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1 Score:   0.646\n",
        "classification report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.78      0.19      0.31       675\n",
        "          2       0.56      0.39      0.46      1432\n",
        "          3       0.71      0.93      0.81      3017\n",
        "\n",
        "avg / total       0.68      0.69      0.65      5124\n",
        "\n",
        "confusion matrix:\n",
        "         Bad  Neutral  Good\n",
        "Bad      131      252   292\n",
        "Neutral   19      563   850\n",
        "Good      17      182  2818\n",
        "\n"
       ]
      }
     ],
     "input": [
      "results = []\n",
      "for clf, name in (\n",
      "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
      "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
      "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
      "        #(KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
      "        (RandomForestClassifier(),\"Forest\"),\n",
      "        #(SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "        #gamma=0.0, kernel='linear', max_iter=-1, probability=False,\n",
      "        #random_state=None, shrinking=True, tol=0.001, verbose=False), \"SVM\")\n",
      "                    ):\n",
      "    print('=' * 80)\n",
      "    print(name)\n",
      "    results.append(benchmark(clf, df))\n",
      "\n",
      "for penalty in [\"l2\", \"l1\"]:\n",
      "    print('=' * 80)\n",
      "    print(\"%s penalty\" % penalty.upper())\n",
      "    # Train Liblinear model\n",
      "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
      "                                            dual=False, tol=1e-3),df))\n",
      "\n",
      "    # Train SGD model\n",
      "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
      "                                           penalty=penalty),df))\n",
      "\n",
      "# Train SGD with Elastic Net penalty\n",
      "print('=' * 80)\n",
      "print(\"Elastic-Net penalty\")\n",
      "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
      "                                       penalty=\"elasticnet\"),df))\n",
      "\n",
      "# Train NearestCentroid without threshold\n",
      "print('=' * 80)\n",
      "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
      "results.append(benchmark(NearestCentroid(),df))\n",
      "\n",
      "# Train sparse Naive Bayes classifiers\n",
      "print('=' * 80)\n",
      "print(\"Naive Bayes\")\n",
      "results.append(benchmark(BernoulliNB(alpha=.01),df))\n",
      "\n",
      "\n",
      "class L1LinearSVC(LinearSVC):\n",
      "\n",
      "    def fit(self, X, y):\n",
      "        # The smaller C, the stronger the regularization.\n",
      "        # The more regularization, the more sparsity.\n",
      "        self.transformer_ = LinearSVC(penalty=\"l1\",\n",
      "                                      dual=False, tol=1e-3)\n",
      "        X = self.transformer_.fit_transform(X, y)\n",
      "        return LinearSVC.fit(self, X, y)\n",
      "\n",
      "    def predict(self, X):\n",
      "        X = self.transformer_.transform(X)\n",
      "        print(LinearSVC.predict(self, X))\n",
      "        return LinearSVC.predict(self, X)\n",
      "\n",
      "print('=' * 80)\n",
      "print(\"LinearSVC with L1-based feature selection\")\n",
      "results.append(benchmark(L1LinearSVC(),df))"
     ],
     "language": "python",
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAu8AAAIxCAYAAAD9t1YOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0/qSA7P9AAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f437c72d7b8>"
       ],
       "metadata": {}
      }
     ],
     "input": [
      "# make some plots\n",
      "%matplotlib inline\n",
      "indices = np.arange(len(results))\n",
      "\n",
      "results = [[x[i] for x in results] for i in range(4)]\n",
      "\n",
      "clf_names, score, training_time, test_time = results\n",
      "training_time = np.array(training_time) / np.max(training_time)\n",
      "test_time = np.array(test_time) / np.max(test_time)\n",
      "\n",
      "plt.figure(figsize=(12, 8))\n",
      "plt.title(\"Score\")\n",
      "plt.barh(indices, score, .2, label=\"score\", color='r')\n",
      "plt.barh(indices + .3, training_time, .2, label=\"training time\", color='g')\n",
      "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='b')\n",
      "plt.yticks(())\n",
      "plt.legend(loc='best')\n",
      "plt.subplots_adjust(left=.25)\n",
      "plt.subplots_adjust(top=.95)\n",
      "plt.subplots_adjust(bottom=.05)\n",
      "\n",
      "for i, c in zip(indices, clf_names):\n",
      "    plt.text(-.3, i, c)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "def benchmarkKFold(clf, text_vectorizer= 'tfi', dim_reduce='Ch2', k_variables=2000, top10=None, feature_names=None, report=None, matrix=None):\n",
      "    \n",
      "    corpus = []\n",
      "    data.ix[:,1].apply(Append)\n",
      "    \n",
      "    if text_vectorizer == 'tfi':\n",
      "        vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english', lowercase=True)\n",
      "    \n",
      "    elif text_vectorizer == 'count':\n",
      "        vectorizer = CountVectorizer(ngram_range=(2,2), lowercase=True)\n",
      "        \n",
      "    X = vectorizer.fit_transform(corpus)\n",
      "\n",
      "    Xdf = pd.DataFrame(X.toarray(),index=corpus,columns=vectorizer.get_feature_names())\n",
      "    Xdf['zzRating'] = df.ix[:,0].values.astype(int)\n",
      "\n",
      "    skf = StratifiedKFold(Xdf[\"zzRating\"], 10)\n",
      "    for train_index, test_index in skf:\n",
      "        X_train, X_test = Xdf.ix[train_index,0:-1], X_test.ix[test_index, 0:-1]\n",
      "        y_train, y_test = Xdf.ix[train_index,0:-1], Xdf.ix[y_test,0:-1]\n",
      "\n",
      "\n",
      "        if dim_reduce == 'Ch2':\n",
      "            ch2 = SelectKBest(chi2, k= k_variables)\n",
      "            b = ch2.fit(X_train, y_train)\n",
      "            X_train, X_test = X_train[:, b.get_support()], X_test[:, b.get_support()]\n",
      "        elif dim_reduce == 'SVD':\n",
      "            svd = TruncatedSVD(n_components=10, random_state=42)\n",
      "            X_train, X_test = svd.fit_transform(X_train), svd.fit_transform(X_test)\n",
      "\n",
      "\n",
      "        clf.fit(X_train, y_train)\n",
      "\n",
      "        pred = clf.predict(X_test)\n",
      "\n",
      "\n",
      "        precision = metrics.precision_score(y_test, pred)\n",
      "        recall = metrics.recall_score(y_test, pred)\n",
      "        f1 = metrics.f1_score(y_test,pred)\n",
      "        \n",
      "        f1_score.append(f1)\n",
      "        recall_score.append(recall)\n",
      "        precision_score.append(precision)\n",
      "        \n",
      "    return numpy.mean(precision_score), numpy.mean(recall_score), numpy.mean(f1_score)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "precision, recall, f1 = benchmarkKFold(RandomForestClassifier(bootstrap=True,\n",
      "            criterion='entropy', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=223, verbose=0))"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {
  "name": "",
  "signature": "sha256:ef3810211fcf1737dd2f512b1eef61ebe0f33468072483b83bff2a11319395e4"
 },
 "nbformat": 3,
 "nbformat_minor": 0
}